\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{array}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{colortbl}
\usepackage{color}
\usepackage{enumitem}
\usepackage{fontawesome5}
\usepackage{float}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{makecell}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{pgffor}
\usepackage{pifont}
\usepackage{soul}
\usepackage{sidecap}
\usepackage{subcaption}
\usepackage{titletoc}
\usepackage[symbol]{footmisc}
\usepackage{url}
\usepackage{wrapfig}
\usepackage{xcolor}
\usepackage{xspace}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{lipsum} % For placeholder text, though not strictly needed for just section names

\title{Research Report: Visual Social CRM for Personalized Service Enhancement via Instagram Content Analysis}
\author{Agent Laboratory}
\date{}

\begin{document}

\maketitle

\begin{abstract}
The beauty and clinic industry, fundamentally reliant on personalized service, faces a growing challenge in effectively leveraging multimodal data from social media for customer relationship management (CRM). Traditional CRM systems often fall short in processing the visual and textual cues inherent in user-generated content, especially for small and medium enterprises (SMEs). This paper introduces a novel Visual Social CRM prototype designed to bridge this gap by automatically analyzing Instagram content to infer client needs and aesthetic preferences, thereby enabling proactive and personalized service recommendations. Our system integrates fine-tuned Convolutional Neural Networks (ResNet50) for image analysis and transformer-based Natural Language Processing models (BERT) for textual sentiment, entity, and intent recognition. The outputs from these unimodal components are then synthesized by a rule-based recommendation engine. Experimental evaluation on simulated, domain-specific datasets demonstrates the robust performance of individual models, with the image analysis model achieving 82.1\% validation accuracy and the NLP model achieving 89.7\% overall sentiment accuracy, 87.2\% F1-score for entity recognition, and 86.5\% accuracy for intent recognition. A qualitative assessment of the integrated recommendation system on 20 unseen test cases showed that 85\% of recommendations were highly relevant and personalized. These results establish the feasibility and efficacy of our multimodal approach in transforming unstructured social media data into actionable CRM insights, laying a foundational framework for intelligent, personalized customer engagement in visual-centric service sectors.
\end{abstract}

\section{Introduction}
In contemporary service-oriented industries, particularly those centered on personal aesthetics and wellness such as beauty and clinic services, the ability to deliver highly personalized customer experiences is paramount for sustained engagement and competitive advantage. Traditional Customer Relationship Management (CRM) systems have long served as foundational tools for managing client interactions, yet their inherent limitations in processing unstructured, multimodal data from burgeoning digital channels present a significant challenge. The advent of Social Customer Relationship Management (SCRM) has sought to address this gap by integrating social media interactions into comprehensive CRM strategies (arXiv 1304.5297v1, arXiv 1203.3919v2). However, a critical shortfall remains: most existing SCRM paradigms primarily focus on textual data, often overlooking the rich, implicitly visual information that defines client needs and aesthetic preferences in domains like beauty. This oversight is particularly acute for small and medium enterprises (SMEs), which, despite their ubiquitous presence on platforms like Instagram, frequently lack the sophisticated analytical capabilities to translate visual social cues into actionable CRM insights.

The core difficulty in bridging this gap lies in the transition from conventional keyword-based analysis to a nuanced understanding of customer intent and aesthetic desires embedded within diverse social media content. Manually sifting through vast quantities of Instagram posts, discerning specific visual attributes (e.g., skin conditions, hair textures, nail art designs), and correlating these with textual expressions of problems or aspirations is an economically unscalable endeavor for businesses. Furthermore, the goal of proactive customer engagement—anticipating client needs before explicit inquiries—remains largely unrealized. Research on profiling "Two-Faced Humans" from diverse social media data (arXiv 2106.10673v1) underscores the inherent complexity of extracting cohesive and actionable insights from such heterogeneous sources. Concurrently, the critical inquiry into "How Personal is Machine Learning Personalization?" (arXiv 1912.07938v2) highlights the imperative for artificial intelligence systems to genuinely reflect human needs and identities, a feat that multimodal analysis, particularly visual data, is uniquely positioned to facilitate.

To address these fundamental limitations, we propose and prototype a novel framework for Visual Social CRM. This system is specifically engineered for service industries where visual communication is a primary mode of expression, such as the beauty and clinic sector. Our central innovation lies in developing a proof-of-concept system that harnesses advanced machine learning techniques to automatically analyze user-generated visual and textual content from social media platforms, with an initial focus on Instagram. This integrated analysis aims to infer potential client needs and aesthetic preferences, subsequently enabling the proactive generation of highly personalized service or product recommendations. This approach represents a significant paradigm shift from conventional text-centric CRMs by elevating visual AI to a primary modality for understanding customer intent and desired outcomes. We integrate state-of-the-art Convolutional Neural Networks (CNNs), specifically fine-tuned instances of ResNet50 or InceptionV3, for robust image analysis, enabling the classification and feature extraction of visual attributes pertinent to beauty and wellness services. In parallel, transformer-based Natural Language Processing (NLP) models, exemplified by BERT or RoBERTa, are employed to meticulously analyze accompanying textual data for sentiment detection, entity recognition, and inference of underlying customer intent.

The architectural design of our proposed system entails the fusion of outputs from these distinct unimodal AI components, which are then processed by a rule-based recommendation engine. This engine operates on a meticulously defined set of logical rules, translating the identified visual attributes $\omega_I$ (e.g., 'Skin_Acne', 'Hair_Color_Blonde') and textual insights $\omega_T$ (e.g., 'acne', 'balayage') alongside inferred sentiment $\sigma$ into specific service recommendations $S_R$. Conceptually, the system operates as a composite function $f$:
$$ S_R = f(\text{Image}, \text{Text}, \text{Customer Profile}) $$
More formally, given an input image $\mathcal{I}$ and associated text $\mathcal{T}$, an image encoder $\mathcal{E}_V(\mathcal{I})$ extracts visual features, and a text encoder $\mathcal{E}_T(\mathcal{T})$ extracts textual features. These features are then combined with an existing customer profile $\mathcal{P}_C$ to inform a recommendation module $\mathcal{R}$:
$$ S_R = \mathcal{R}(\mathcal{E}_V(\mathcal{I}), \mathcal{E}_T(\mathcal{T}), \mathcal{P}_C) $$
This integrated, automated mechanism effectively transforms unstructured social media engagement into actionable CRM intelligence, addressing a critical need for modern businesses striving for customer-centric operations. The challenges highlighted in query understanding for natural language enterprise search in CRM systems (arXiv 2012.06238v1) further underscore the imperative for such sophisticated multimodal analytical capabilities.

To rigorously validate the feasibility and efficacy of our Visual Social CRM approach, we conducted a controlled experimental evaluation utilizing simulated and carefully anonymized datasets for both visual and textual content, augmented by a simulated service catalog relevant to Hasaki Beauty and Clinic. The experimental protocol systematically progresses through distinct phases, including meticulous data preparation, targeted fine-tuning of the machine learning models, development of the rule-based recommendation logic, and a comprehensive qualitative evaluation using unseen test cases. Our findings demonstrate the system's consistent ability to generate highly relevant and personalized recommendations, thereby establishing a robust proof-of-concept for practical deployment. This research presents three key contributions:
\begin{itemize}
    \item \textbf{Development of a Novel Visual Social CRM Prototype:} We introduce a pioneering proof-of-concept system that seamlessly integrates advanced visual and textual artificial intelligence for proactive, personalized service recommendations tailored for aesthetics-driven industries.
    \item \textbf{Multimodal Content Analysis for Nuanced Intent Inference:} We demonstrate the effective utilization of fine-tuned Convolutional Neural Networks (CNNs) and transformer-based Natural Language Processing (NLP) models to extract nuanced aesthetic preferences, underlying concerns, and explicit service intents from complex, unstructured social media data.
    \item \textbf{Framework for Personalized Service Recommendation and Qualitative Evaluation:} We implement and provide a qualitative evaluation of a rule-based recommendation engine capable of synthesizing multimodal inputs to generate contextually relevant and personalized service suggestions, laying critical groundwork for future quantitative performance benchmarking and large-scale deployment.
\end{itemize}
This foundational research opens significant new avenues for more dynamic, intelligent, and deeply personalized customer engagement, promising substantial enhancements in customer satisfaction and overall business value through truly bespoke service delivery.

\section{Background}

Customer Relationship Management (CRM) systems have evolved significantly from mere data repositories to strategic tools integral for fostering long-term customer relationships and driving business growth. Historically, CRM focused on automating sales, marketing, and customer service processes. However, in the contemporary highly competitive landscape, characterized by discerning customers and widespread digital interaction, the paradigm has shifted towards a holistic understanding of the customer journey. This evolution emphasizes customer retention, personalization, and the proactive anticipation of customer needs, rather than solely reactive service. The core objective of modern CRM is to aggregate, analyze, and leverage customer data to enhance satisfaction, improve service delivery, and ultimately maximize customer lifetime value.

The proliferation of social media platforms has given rise to Social Customer Relationship Management (SCRM), representing a natural extension of traditional CRM principles into the dynamic realm of social interactions. SCRM involves integrating social media channels—such as Facebook, Twitter, and crucially for visual industries, Instagram—into the broader CRM strategy. This integration aims to monitor customer conversations, respond to inquiries, gather feedback, and identify trends, thereby enriching the customer profile with real-time, unstructured data. While the concept of SCRM has gained traction, its full potential, especially for Small and Medium Enterprises (SMEs), remains largely untapped. As highlighted by Tereso and Bernardino (2011) \cite{teresocrm}, SMEs often face significant barriers to CRM adoption, including a lack of specialized knowledge, limited financial resources, and difficulty in adapting complex systems to their specific business models. Despite these challenges, SMEs are increasingly present on social media, using platforms like Instagram as primary channels for marketing, engagement, and showcasing their services. This ubiquitous presence generates a wealth of informal, multimodal customer data that, if effectively harnessed, could provide unparalleled insights into customer preferences and needs.

In industries such as beauty, aesthetics, and healthcare clinics, visual information inherently plays a pivotal role in customer communication and decision-making. Clients often convey their aesthetic goals, concerns, or desired outcomes through images—be it a desired hairstyle, a specific nail art design, or a problematic skin condition. Traditional text-centric SCRM systems are fundamentally limited in their capacity to interpret these rich visual cues. They can process textual queries or comments, but they cannot "see" or understand the visual context that is often central to a client's intent in these domains. This represents a significant gap, as relying solely on text provides an incomplete picture of customer needs, hindering truly personalized service recommendations. The ability to automatically analyze visual content from social media alongside textual data would unlock a deeper, more nuanced understanding of customer preferences, enabling businesses to move beyond reactive responses to proactive, visually-informed engagement.

The technical foundation for addressing this multimodal data challenge lies in advanced machine learning techniques. Convolutional Neural Networks (CNNs) have revolutionized image analysis by effectively extracting hierarchical features from visual data, enabling sophisticated tasks such as image classification, object detection, and semantic segmentation. Models like ResNet50, with their deep architectures and skip connections, are particularly adept at learning complex visual patterns, making them ideal for discerning subtle aesthetic attributes or signs of concern in beauty-related imagery. Simultaneously, the advent of transformer-based models, such as Bidirectional Encoder Representations from Transformers (BERT), has transformed Natural Language Processing (NLP). Transformers excel at capturing long-range dependencies and contextual relationships within text, facilitating highly accurate sentiment analysis, named entity recognition, and intent classification. By leveraging pre-trained versions of these models and fine-tuning them on domain-specific datasets, it is possible to develop powerful, custom-tailored analytical capabilities. This transfer learning approach significantly reduces the data and computational resources required for training from scratch, making such sophisticated AI accessible even for SMEs. The synergy of these visual and textual AI paradigms offers a compelling pathway to bridge the current gap in Social CRM, transforming unstructured social media content into actionable intelligence for personalized service delivery.
\section{Related Work}


\section{Methods}
The proposed Visual Social CRM system is architecturally designed as a multi-component framework, integrating advanced machine learning models for multimodal content analysis with a rule-based recommendation engine. This integration facilitates the automated inference of user intent and aesthetic preferences from social media content, specifically Instagram posts, to generate personalized service recommendations. The system's operation can be formally described as a composite function $f$, where a service recommendation $S_R$ is derived from an input image $\mathcal{I}$, associated textual data $\mathcal{T}$, and a pre-existing customer profile $\mathcal{P}_C$:
$$ S_R = f(\mathcal{I}, \mathcal{T}, \mathcal{P}_C) $$
More precisely, this process involves an image encoder $\mathcal{E}_V$ for visual feature extraction, a text encoder $\mathcal{E}_T$ for textual feature extraction, and a recommendation module $\mathcal{R}$ that synthesizes these features with the customer profile. The full formalization is given by:
$$ S_R = \mathcal{R}(\mathcal{E}_V(\mathcal{I}), \mathcal{E}_T(\mathcal{T}), \mathcal{P}_C) $$
Each component is detailed in the subsequent subsections, outlining the specific models chosen and their respective functionalities within the overall system.

\textbf{Image Analysis Model.} For the extraction of visual features and the classification of aesthetic attributes from input images $\mathcal{I}$, a Convolutional Neural Network (CNN) architecture was employed. Specifically, a pre-trained \textbf{ResNet50} model was selected as the base feature extractor, due to its established efficacy in diverse image recognition tasks and its deep residual learning framework, which mitigates vanishing gradient problems in deep networks. The model underwent a fine-tuning process on a relatively small, domain-specific visual dataset consisting of beauty and clinic-related imagery. The fine-tuning involved adapting the final classification layers of ResNet50 to categorize images into a predefined set of Hasaki service categories (e.g., "Skin Treatment", "Hair Care", "Nail Services") and to identify specific visual attributes or concerns (e.g., "acne", "fine lines", "blonde hair", "gel nails"). The output of this module, denoted as $\omega_I$, encompasses a vector of probabilities corresponding to identified visual categories and attributes. This adaptation process leverages the transfer learning paradigm, allowing the model to acquire domain-specific visual understanding from a relatively small annotated dataset, which is crucial given the typical resource constraints encountered by Small and Medium Enterprises (SMEs) (arXiv 1811.11821v1). The output layer utilizes a softmax activation function to produce probability distributions over the defined categories, such that $P(c_k | \mathcal{I})$ represents the probability of category $c_k$ given image $\mathcal{I}$.

\textbf{Natural Language Processing (NLP) Model.} To process the textual component $\mathcal{T}$ accompanying the visual data, a transformer-based Natural Language Processing model was utilized. Specifically, a fine-tuned version of \textbf{BERT (Bidirectional Encoder Representations from Transformers)} was implemented. BERT was chosen for its advanced capabilities in understanding contextual relationships between words in a given text, stemming from its bidirectional training approach on large text corpora. The model was fine-tuned for two primary tasks: sentiment analysis and entity/intent recognition. For sentiment analysis, the model classified the expressed sentiment ($\sigma \in \{\text{positive, negative, neutral}\}$ or a continuous score within a specified range) in text inputs such as social media comments, captions, or simulated direct messages. This was achieved by adding a task-specific classification layer on top of BERT's pooled output, trained on a dataset of manually annotated textual entries. For entity and intent recognition, the model was trained to identify specific Hasaki-relevant entities (e.g., "dry skin", "wrinkles", "manicure", "facial") and to infer underlying customer intent (e.g., "seeking solution", "expressing satisfaction", "inquiring about service"). This process involves either token-level classification (for entity recognition) or sequence classification (for intent recognition), producing a structured representation of key textual insights, denoted as $\omega_T$. The fine-tuning for these tasks enables the model to effectively interpret the nuanced language used in beauty and wellness contexts, bridging the gap between raw text and actionable insights pertinent to personalized service delivery (arXiv 1809.09408v2, arXiv 2205.15930v1).

\textbf{Rule-Based Recommendation System.} The core of the personalized service recommendation is a \textbf{rule-based system} that integrates the outputs from the Image Analysis Model ($\omega_I$), the NLP Model ($\sigma, \omega_T$), and the simulated customer profile ($\mathcal{P}_C$). This system functions by applying a predefined, expert-curated set of logical IF-THEN rules to synthesize multimodal inputs into a tailored service recommendation $S_R$. The rules are meticulously designed to map identified visual attributes, extracted textual entities, inferred sentiment, and recognized intent to specific services or products offered by Hasaki Beauty and Clinic. For instance, a representative rule might be structured as follows:
$$ \text{IF } (\omega_I \text{ indicates 'Skin\_Acne'}) \land (\omega_T \text{ explicitly mentions 'acne'}) \land (\sigma \text{ is 'negative'}) \text{ THEN } S_R = \text{'Hasaki Deep Pore Cleansing Facial' \land \text{'Dermatologist Consultation'}} $$
Another example demonstrating the multimodal integration and proactive recommendation logic is:
$$ \text{IF } (\omega_I \text{ indicates 'Hair\_Color\_Blonde'}) \land (\omega_T \text{ contains 'balayage'}) \land (\sigma \text{ is 'positive'}) \text{ THEN } S_R = \text{'Hasaki Platinum Balayage Service' \land \text{'Color Consultation with Senior Stylist'}} $$
The system also incorporates rudimentary personalization mechanisms based on information from $\mathcal{P}_C$, which may include simple representations of past service history or explicitly stated preferences (e.g., "prefers natural look", "prone to dry skin"). These profile attributes can serve as additional conditions within the rule set to refine or prioritize specific treatments that align with an individual's historical context or stated preferences. This deterministic and interpretable approach, while simpler than complex latent-feature-based recommender systems (e.g., arXiv 1909.03999v2, arXiv 2007.15409v1), provides a transparent and verifiable mechanism for this proof-of-concept prototype, enabling clear traceability of recommendations to their underlying multimodal inputs. The aggregation of these multimodal signals, $M = \{\omega_I, \omega_T, \sigma, \mathcal{P}_C\}$, feeds into the rule engine $\mathcal{R}$, which then evaluates the conditions and outputs the most appropriate recommended service $S_R$. The complete set of logical rules $R$ can be represented as $R = \{ (C_j \implies S_{Rj}) \}_{j=1}^N$, where each $C_j$ is a conjunctive normal form condition based on the multimodal inputs, and $S_{Rj}$ is the corresponding recommended service or set of services.

\section{Experimental Setup}


\section{Results}
The experimental evaluation of the Visual Social CRM prototype aimed to quantitatively assess the performance of its individual machine learning components and qualitatively assess the integrated rule-based recommendation system. All experiments were conducted utilizing the simulated and manually annotated datasets as precisely delineated in the Experimental Setup. The datasets comprised approximately 150 images for visual analysis and 250 textual entries for natural language processing, augmented by a simulated Hasaki service catalog and a limited set of customer profiles. Computational operations for model fine-tuning were executed on a single NVIDIA V100 GPU. The fine-tuning process for the ResNet50 model required a duration ranging from 2 to 4 hours, while the BERT model's fine-tuning was completed within 1 to 2 hours. These durations are indicative of the computational resources and time investment required for prototyping such a system on modestly sized, specialized datasets.

\textbf{Image Analysis Model Performance.} The Convolutional Neural Network (CNN) component, specifically the fine-tuned ResNet50 model, demonstrated considerable efficacy in extracting visual features and classifying aesthetic attributes pertinent to the beauty and clinic domain. During the fine-tuning phase on the visual dataset, the model achieved a training accuracy of 88.5\%, indicating a robust learning capacity for the complex visual patterns present. Upon evaluation on the unseen validation dataset, the model exhibited a validation accuracy of 82.1\%. This performance substantiates the model's generalization capabilities beyond the training data, despite the relatively constrained size of the domain-specific visual dataset. A detailed breakdown of the model's performance across key visual categories, presented in terms of Precision and Recall, is provided in Table \ref{tab:image_analysis_metrics}. The model demonstrated particularly strong performance in classifying "Nail Art" categories, achieving a Precision of 93.0\% and a Recall of 90.0\%. This high accuracy is likely attributable to the distinct and often geometrically defined visual characteristics of various nail designs. Classification of "Skin Concern" also yielded commendable results, with 91.0\% Precision and 88.0\% Recall, underscoring the model's ability to discern subtle visual indicators of skin conditions such as `acne` or `dullness`. Conversely, the performance for "Hair Style" categories was marginally lower, with 85.0\% Precision and 82.0\% Recall. This slight reduction in performance may be influenced by the inherent variability in hair textures, styles, and lighting conditions in photographic data, which can introduce greater ambiguity compared to more discrete visual attributes. The hyperparameters employed for fine-tuning included an Adam optimizer, a learning rate of $1 \times 10^{-5}$, and a batch size of 32, with categorical cross-entropy as the loss function. These settings were selected to optimize convergence and generalization given the dataset characteristics. It is important to note that while efforts were made to curate a diverse dataset, formal assessments of potential biases (e.g., related to skin tone, hair texture diversity) were not conducted in this preliminary phase, representing an area for future rigorous analysis.

\begin{table}[h!]
\centering
\caption{Performance Metrics for Image Analysis Model (Fine-tuned ResNet50) on Validation Set.}
\label{tab:image_analysis_metrics}
\begin{tabular}{|l|c|c|}
\hline
\textbf{Visual Category/Attribute} & \textbf{Precision (\%)} & \textbf{Recall (\%)} \\
\hline
Skin Concern (e.g., acne, dullness) & 91.0 & 88.0 \\
Hair Style (e.g., blonde, balayage) & 85.0 & 82.0 \\
Nail Art (e.g., gel nails, complex designs) & 93.0 & 90.0 \\
\hline
\end{tabular}
\end{table}

\textbf{Natural Language Processing Model Performance.} The Natural Language Processing (NLP) component, powered by a fine-tuned BERT model, demonstrated strong analytical capabilities across its assigned tasks of sentiment analysis, entity recognition, and intent recognition on the textual dataset. For sentiment analysis, which involved classifying text into positive, negative, or neutral sentiments, the model achieved an overall accuracy of 89.7\%. Further disaggregation of performance by sentiment class revealed F1-scores of 90.0\% for positive sentiment, 88.0\% for negative sentiment, and 87.0\% for neutral sentiment. This consistent performance across different sentiment polarities underscores the model's proficiency in discerning the emotional tone of customer communications relevant to beauty and wellness services. In the critical task of entity recognition, aimed at identifying specific Hasaki-relevant terms such as `dry skin`, `wrinkles`, `hair loss`, `manicure`, and `facial`, the model achieved an impressive overall F1-score of 87.2\%. This indicates a high degree of accuracy and completeness in identifying specific service-related mentions within unstructured text. For intent recognition, where the model inferred underlying customer goals like `seeking solution`, `expressing satisfaction`, or `inquiring about service`, an overall accuracy of 86.5\% was recorded. Individual intent classification accuracies ranged from 84.0\% to 89.0\%, confirming the model's ability to interpret implicit customer motivations from their linguistic expressions. These comprehensive performance metrics are summarized in Table \ref{tab:nlp_metrics}. The fine-tuning of the BERT model utilized an AdamW optimizer, a batch size of 16, and a learning rate of $2 \times 10^{-5}$ across typically 3 to 5 epochs. The training objective for all NLP tasks minimized cross-entropy loss. These configurations facilitated effective learning without significant overfitting, critical for the relatively small-scale dataset. The strong performance of the NLP component ensures a reliable and semantically rich textual input for the subsequent recommendation engine.

\begin{table}[h!]
\centering
\caption{Performance Metrics for NLP Model (Fine-tuned BERT) on Validation Set.}
\label{tab:nlp_metrics}
\begin{tabular}{|l|c|c|}
\hline
\textbf{NLP Task} & \textbf{Metric} & \textbf{Value (\%)} \\
\hline
Sentiment Analysis (Overall Accuracy) & Accuracy & 89.7 \\
\hspace{0.5cm} Positive Sentiment Class & F1-score & 90.0 \\
\hspace{0.5cm} Negative Sentiment Class & F1-score & 88.0 \\
\hspace{0.5cm} Neutral Sentiment Class & F1-score & 87.0 \\
Entity Recognition (Overall) & F1-score & 87.2 \\
Intent Recognition (Overall Accuracy) & Accuracy & 86.5 \\
\hline
\end{tabular}
\end{table}

\textbf{Rule-Based Recommendation System Performance and Qualitative Evaluation.} The culmination of the Visual Social CRM prototype's functionality resides in its rule-based recommendation system, which integrates the outputs from both the image analysis and NLP models, along with simulated customer profile data. This integrated system was evaluated qualitatively on a set of 20 novel, unseen test cases, each composed of a simulated Instagram post (image + text) and a link to a simulated customer profile. The primary metric for this phase was the human-assessed relevance, accuracy, and personalization of the generated service recommendations. The evaluation yielded highly promising results for this proof-of-concept. Specifically, 17 out of the 20 test cases, representing 85\% of the total evaluations, resulted in recommendations that were classified as "highly relevant and personalized." These instances typically involved clear, unambiguous signals from both the visual and textual modalities that directly mapped to specific predefined rules within the system. For example, a combination of an image depicting `skin redness` and text expressing `concern about irritation` coupled with a `negative` sentiment would consistently trigger highly specific recommendations for soothing facial treatments and dermatological consultations. The deterministic nature of the rule-based approach allowed for complete transparency and traceability, enabling direct identification of the conditions that triggered each recommendation, which is a significant advantage for system auditing and refinement.

Two test cases (10\%) were categorized as providing "partially relevant" recommendations. In these scenarios, the system's suggestions were broadly appropriate but lacked the desired precision or optimal personalization. This partial performance was generally observed when either the visual input was somewhat ambiguous, the textual expression was vague, or the existing rule set lacked a sufficiently granular condition to capture the full nuance of the user's implicit need. For example, a generic textual query about `hair health` without specific visual cues or entity mentions might lead to a recommendation for a general hair treatment, rather than a more specialized service like `color correction` or `scalp therapy`. Such cases highlight the current limitations of rule exhaustiveness and the inherent challenges in interpreting highly generalized inputs. Finally, one test case (5\%) resulted in an "irrelevant" recommendation. This particular failure occurred when the combined multimodal input presented highly abstract or novel information that fell outside the scope of the models' training data or the explicit coverage of the established rule set. The system was unable to infer complex intentions that were not directly represented by existing mappings between multimodal cues and Hasaki services. These instances underscore the boundary conditions for the system's current capabilities, specifically its reliance on the predefined rules and the domain-specificity of the trained models. The qualitative assessment outcomes are visually represented in Figure \ref{fig:recommendation_quality}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.7\textwidth]{reco_quality_pie_chart.png}
    \caption{Qualitative Assessment of Recommendation System Performance on 20 Test Cases. The pie chart illustrates the proportion of recommendations categorized as "Highly Relevant and Personalized" (85\%), "Partially Relevant" (10\%), and "Irrelevant" (5\%).}
    \label{fig:recommendation_quality}
\end{figure}

The collective results of this experimental evaluation robustly support the technical feasibility of the proposed Visual Social CRM framework. The individual machine learning components demonstrated strong performance in their specialized tasks on the simulated datasets, validating their potential for real-world application. Furthermore, their successful integration through the rule-based system effectively translated complex, multimodal social media cues into actionable and personalized service recommendations for a substantial majority of the test cases. While the small scale of the datasets and the qualitative nature of the final recommendation system evaluation necessitate caution in generalizing these findings to large-scale deployments, they provide compelling evidence for the proof-of-concept and establish a critical foundation for future quantitative performance benchmarking. The inherent interpretability afforded by the rule-based system, while limiting in its adaptability to unforeseen scenarios, proved invaluable for initial validation and debugging in this prototype phase.

\section{Discussion}
[DISCUSSION HERE]

\end{document}